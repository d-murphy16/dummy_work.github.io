{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"9ku0h8OsoHJz"},"source":["<p align=\"left\"><img src=\"https://mospi.gov.in/sites/default/files/logo.png\" width=\"500\" height=\"100\" /></p>\n","\n","#  **Time-Use Survey & Consumer Pyramid**<br>\n","#### <p style= 'text-align:left'>Prepared by: ---- </p>                                          \n","---"]},{"cell_type":"markdown","metadata":{"id":"NWvRwRdGoK5Y"},"source":["### **Table of Contents**\n","\n","1. [**Introduction**](#Section1)<br>\n","\n","2. [**Data Acquisition & Description**](#Section4)<br>\n","\n","3. [**Exploratory Data Analysis**](#Section6)<br>\n","\n","4. [**Summarization**](#Section7)<br>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iACv_4iIoaLi"},"source":["<a name = Section1></a>\n","### **1. Introduction**\n","---\n","--"]},{"cell_type":"markdown","metadata":{"id":"ys9Qb4OlpzvZ"},"source":["\n","<a name = Section4></a>\n","### **2. Data Acquisition & Description**\n","\n","##### This section is emphasised on the accquiring the data, cleaning it and obtain some descriptive information out of it.\n","---\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# #Installing/Upgrading Libraries\n","\n","# !pip install pandas\n","# !pip install dask pandas\n","# !pip install scipy\n","\n","# !pip install -q datascience                                         # Package that is required by pandas profiling\n","# !pip install ydata-profiling\n","\n","# !pip install tabula-py\n","# !pip install nbconvert\n","# !pip install geopy"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Importing Libraries\n","# -------------------------------------------------------------------------------------------------------------------------------\n","# Importing library for scientific calculations\n","import scipy.stats as st\n","# Importing package pandas (For Panel Data Analysis)\n","import pandas as pd\n","# import dask.dataframe as dd\n","# Import Pandas Profiling (To generate Univariate Analysis)\n","# from ydata_profiling import ProfileReport\n","# -------------------------------------------------------------------------------------------------------------------------------\n","# Importing package numpys (For Numerical Python)\n","import numpy as np\n","# -------------------------------------------------------------------------------------------------------------------------------\n","# Importing pyplot interface to use matplotlib\n","import matplotlib.pyplot as plt\n","# Importing seaborn library for interactive visualization\n","import seaborn as sns\n","# -------------------------------------------------------------------------------------------------------------------------------\n","#Importing Tabula to read tables from pdf\n","# from tabula import read_pdf\n","# -------------------------------------------------------------------------------------------------------------------------------\n","from datetime import datetime, timedelta\n","# -------------------------------------------------------------------------------------------------------------------------------\n","import nbconvert\n","# -------------------------------------------------------------------------------------------------------------------------------\n","import warnings                                                     # Importing warning to disable runtime warnings\n","warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once\n","# -------------------------------------------------------------------------------------------------------------------------------\n","import os\n","import glob\n","\n","# from geopy.geocoders import Nominatim\n","# geolocator = Nominatim(user_agent=\"MyApp\")"]},{"cell_type":"markdown","metadata":{},"source":["##### **Fetching & Cleaning Consumer Pyramid**:"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/Users/gulatii16/Library/CloudStorage/GoogleDrive-himanshu.gulatii16@gmail.com/My Drive/0 g [n]/1 Focus Areas/3 Data Science/CROPPED VARIABLES_MERGED.dta'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cp_dummy \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/gulatii16/Library/CloudStorage/GoogleDrive-himanshu.gulatii16@gmail.com/My Drive/0 g [n]/1 Focus Areas/3 Data Science/CROPPED VARIABLES_MERGED.dta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m10\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/stata.py:2150\u001b[0m, in \u001b[0;36mread_stata\u001b[0;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[0;32m-> 2150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/stata.py:1708\u001b[0m, in \u001b[0;36mStataReader.read\u001b[0;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1706\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1707\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 1708\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1710\u001b[0m     \u001b[38;5;66;03m# Handle options\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/stata.py:1182\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/stata.py:1195\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[1;32m   1189\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[1;32m   1193\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1194\u001b[0m     )\n\u001b[0;32m-> 1195\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_path_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gulatii16/Library/CloudStorage/GoogleDrive-himanshu.gulatii16@gmail.com/My Drive/0 g [n]/1 Focus Areas/3 Data Science/CROPPED VARIABLES_MERGED.dta'"]}],"source":["cp_dummy = pd.read_stata(filepath_or_buffer= '/Users/gulatii16/Library/CloudStorage/GoogleDrive-himanshu.gulatii16@gmail.com/My Drive/0 g [n]/1 Focus Areas/3 Data Science/CROPPED VARIABLES_MERGED.dta',iterator= False)\n","pd.set_option('display.max_columns',10)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["sorted_cp_dummy = cp_dummy.sort_values(by=['PID','TIME'])\n","sorted_cp_dummy['TIME'] = sorted_cp_dummy['TIME'] -1 \n","\n","sorted_cp_dummy = sorted_cp_dummy[(sorted_cp_dummy['relation_with_hoh'] == 'HOH') | (sorted_cp_dummy['relation_with_hoh'] == 'Spouse') | (sorted_cp_dummy['relation_with_hoh'] == 'Son') | (sorted_cp_dummy['relation_with_hoh'] == 'Daughter') | (sorted_cp_dummy['relation_with_hoh'] == 'Son-in-law') |  (sorted_cp_dummy['relation_with_hoh'] == 'Daughter-in-law')]\n","\n","code_mapping = {'Widowed': 8, 'Married': 5, 'Unmarried': 7,'Not Applicable': 6,'Divorced/Separated': 4}\n","sorted_cp_dummy['marital_status_code'] = sorted_cp_dummy['marital_status'].map(code_mapping)\n","\n","sorted_cp_dummy['lag_marital_status_code'] = sorted_cp_dummy.groupby(by=['PID'])[['marital_status_code']].shift(1)\n","sorted_cp_dummy['lead_marital_status_code'] = sorted_cp_dummy.groupby(by=['PID'])[['marital_status_code']].shift(-1)\n","\n","sorted_cp_dummy['married_to_widow'] = np.where((sorted_cp_dummy['lag_marital_status_code'] == 5) & (sorted_cp_dummy['marital_status_code'] == 8), True, False)\n","sorted_cp_dummy['married_to_widow_filtered'] = np.where(((sorted_cp_dummy['lag_marital_status_code'] == 5) & (sorted_cp_dummy['marital_status_code'] == 8)) & ((sorted_cp_dummy['relation_with_hoh'] == 'HOH') | (sorted_cp_dummy['relation_with_hoh'] == 'Spouse')) & ((sorted_cp_dummy['age_yrs'] >= 12) & (sorted_cp_dummy['age_yrs'] <= 75)), True, False)\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['married_to_widow_filtered'].value_counts()\n","# sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['PID'].nunique()\n","\n","#13803/14437\n","#11702/12284\n","\n","# Basically, few PIDs have multiple maried to widow status true, which seems to be an outlier & needs to be removed\n","\n","PID_married_to_widow = sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['PID'].value_counts().to_frame().reset_index()\n","PID_married_to_widow = PID_married_to_widow[PID_married_to_widow['count']>1]\n","PID_to_remove_list = PID_married_to_widow['PID'].to_list()\n","# len(PID_to_remove_list)\n","\n","# 1828/1882 PIDs need to be removed because they reported multiple change in married to widow status\n","\n","sorted_cp_dummy = sorted_cp_dummy[~sorted_cp_dummy['PID'].isin(PID_to_remove_list)]\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['PID'].nunique()\n","# sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['hh_id'].nunique()\n","\n","# 9874/10402 shocks (unique PIDs with status change only once) happened in 9848/10360 HHIDs\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['hh_id'].value_counts().to_frame()['count'].value_counts()\n","\n","# count\n","# 1    9822/10318\n","# 2      26/42\n","\n","# 2 deaths happen in 26/42 HHIDs out of 9948/10360 HHIDs\n","\n","shock_hhids = sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['hh_id'].value_counts().to_frame().reset_index()\n","sorted_cp_dummy['whether_shock_hhid'] = np.where(sorted_cp_dummy['hh_id'].isin(shock_hhids['hh_id']), True, False)\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['whether_shock_hhid'] == True]['PID'].nunique()\n","# 9874/10402 shocks happened in 9848/10360 HHIDs affected 35884/33030 individuals (226316/228458 observations, since not all PIDs have all 11 waves)\n","\n","shock_pids = sorted_cp_dummy.loc[sorted_cp_dummy['married_to_widow_filtered'] == True]['PID'].value_counts().to_frame().reset_index()\n","sorted_cp_dummy['whether_shock_PIDs'] = np.where(sorted_cp_dummy['PID'].isin(shock_pids['PID']), True, False)\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['whether_shock_PIDs'] == True]['PID'].count()\n","# 9874/10402 shocks meaning 9874/10402 people died which have a total of 79344/80022 observations (pre & post shock)\n","\n","sorted_cp_dummy['shock_wave_num_statuschangePID'] = np.where(sorted_cp_dummy['married_to_widow_filtered'] == True,sorted_cp_dummy['TIME'],0)\n","# sorted_cp_dummy['shock_wave_num_statuschangePID'].value_counts()\n","#checked: value copied to 9874/10402 PIDs whose satus got changed\n","\n","representative_values = sorted_cp_dummy.groupby('hh_id')['shock_wave_num_statuschangePID'].max()\n","sorted_cp_dummy['shock_wave_num_allAffectedPID'] = np.where(sorted_cp_dummy['whether_shock_hhid'] == True, sorted_cp_dummy['hh_id'].map(representative_values),0)\n","# sorted_cp_dummy['shock_wave_num_allAffectedPID'].value_counts()\n","#checked: value copied to 226316/228458 observations corresponding to 35884/80022 PIDs of 9848/10360 HHIDs\n","\n","sorted_cp_dummy['current_time-shock_time'] = np.where(sorted_cp_dummy['whether_shock_hhid'] == True, sorted_cp_dummy['TIME']-sorted_cp_dummy['shock_wave_num_allAffectedPID'],np.NaN)\n","sorted_cp_dummy['pre_to_post_shock_status'] = np.where(sorted_cp_dummy['current_time-shock_time']>=0,1,np.where(sorted_cp_dummy['current_time-shock_time']<0,0,np.NaN))\n","\n","# sorted_cp_dummy['pre_to_post_shock_status'].value_counts()\n","# Out of 226316/228458 observations of 35884/33030 PIDs in 9848/10360 hhids, 99012/100796 observations are after shock observations\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['whether_shock_PIDs']==True].groupby(by=['PID'])[['gender']].nunique()[['gender']].value_counts()\n","# gender\n","# 1         10380\n","# 2            22\n","# 22 directly affected people have 2 genders reported in different waves, hence, hhids of these people need to be removed\n","\n","df = sorted_cp_dummy.loc[sorted_cp_dummy['whether_shock_PIDs']==True].groupby(by=['PID'])[['gender']].nunique()[['gender']]\n","df = df[df['gender']>1]\n","PID_directlyAffected_to_remove_list = df[['gender']].index.to_list()\n","hhid_directlyAffected_to_remove_list = sorted_cp_dummy[sorted_cp_dummy['PID'].isin(PID_directlyAffected_to_remove_list)]['hh_id'].to_list()\n","\n","sorted_cp_dummy = sorted_cp_dummy[~sorted_cp_dummy['hh_id'].isin(hhid_directlyAffected_to_remove_list)]\n","\n","# sorted_cp_dummy['PID'].nunique()\n","# sorted_cp_dummy.groupby(by=['PID'])[['gender']].nunique()[['gender']].value_counts()\n","# 506129 unique people are there, out of which 1056 have 2 genders reported in different waves, hence being removed.\n","\n","df = sorted_cp_dummy.groupby(by=['PID'])[['gender']].nunique()[['gender']]\n","df = df[df['gender']>1]\n","PID_ALL_to_remove_list = df[['gender']].index.to_list()\n","hhid_ALL_to_remove_list = sorted_cp_dummy[sorted_cp_dummy['PID'].isin(PID_ALL_to_remove_list)]['hh_id'].to_list()\n","\n","# sorted_cp_dummy[(sorted_cp_dummy['PID'].isin(PID_ALL_to_remove_list)) & (sorted_cp_dummy['whether_shock_hhid'] == True)]['PID'].nunique()\n","\n","sorted_cp_dummy = sorted_cp_dummy[~sorted_cp_dummy['hh_id'].isin(hhid_ALL_to_remove_list)]\n","\n","# sorted_cp_dummy.loc[sorted_cp_dummy['whether_shock_hhid'] == True]['PID'].nunique()\n","\n","# Unique PIDs (with shock) have been reduced from 33030 to 32666 which is 364\n","# Out of these 149 PIDs (with shock) removed, 22 are directly affected & 342 are indirectly affected\n","# Out of these 342 indirectly affected, 287 don't belong to hhids where gender of directly affected person changes\n","# Hence, 22+55 people removed from hhids where directly affected person has gender changed & 287 elsewhere\n","# In total, 364 PIDs are removed"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[],"source":["religion_mode_frame = sorted_cp_dummy.groupby(by = ['PID'])['religion'].agg(lambda x: x.mode().iat[0] if not x.mode().empty else None).to_frame()\n","religion_mode_frame = religion_mode_frame.reset_index()\n","religion_mode_frame.rename(columns={'religion':'new_religion'},inplace = True)\n","sorted_cp_dummy =  pd.merge(sorted_cp_dummy, religion_mode_frame[['PID', 'new_religion']], on='PID', how='left')\n","\n","religion_mode_frame = sorted_cp_dummy.groupby(by = ['PID'])['caste'].agg(lambda x: x.mode().iat[0] if not x.mode().empty else None).to_frame()\n","religion_mode_frame = religion_mode_frame.reset_index()\n","religion_mode_frame.rename(columns={'caste':'new_caste'},inplace = True)\n","sorted_cp_dummy =  pd.merge(sorted_cp_dummy, religion_mode_frame[['PID', 'new_caste']], on='PID', how='left')\n","\n","religion_mode_frame = sorted_cp_dummy.groupby(by = ['PID'])['caste_category'].agg(lambda x: x.mode().iat[0] if not x.mode().empty else None).to_frame()\n","religion_mode_frame = religion_mode_frame.reset_index()\n","religion_mode_frame.rename(columns={'caste_category':'new_caste_category'},inplace = True)\n","sorted_cp_dummy =  pd.merge(sorted_cp_dummy, religion_mode_frame[['PID', 'new_caste_category']], on='PID', how='left')"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["sorted_cp_dummy['daughter_son'] = np.where(sorted_cp_dummy['relation_with_hoh']=='Daughter',1,np.where(sorted_cp_dummy['relation_with_hoh']=='Son',0,np.NaN))"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[{"data":{"text/plain":["total_ts\n","24.0    3473019\n","0.0      173755\n","16.0         48\n","17.0         10\n","18.0          7\n","15.0          6\n","15.5          4\n","21.0          3\n","20.5          3\n","20.0          3\n","16.5          2\n","19.0          2\n","14.0          2\n","18.5          1\n","17.5          1\n","Name: count, dtype: int64"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["# setting negative ts to zero\n","sorted_cp_dummy['ts_on_indoor_entmt'] = np.where(sorted_cp_dummy['ts_on_indoor_entmt']<0,np.NaN,sorted_cp_dummy['ts_on_indoor_entmt'])\n","sorted_cp_dummy['ts_on_learning'] = np.where(sorted_cp_dummy['ts_on_learning']<0,np.NaN,sorted_cp_dummy['ts_on_learning'])\n","sorted_cp_dummy['ts_on_oth_activities_for_self'] = np.where(sorted_cp_dummy['ts_on_oth_activities_for_self']<0,np.NaN,sorted_cp_dummy['ts_on_oth_activities_for_self'])\n","sorted_cp_dummy['ts_on_outdoor_sports'] = np.where(sorted_cp_dummy['ts_on_outdoor_sports']<0,np.NaN,sorted_cp_dummy['ts_on_outdoor_sports'])\n","sorted_cp_dummy['ts_on_religious_activities'] = np.where(sorted_cp_dummy['ts_on_religious_activities']<0,np.NaN,sorted_cp_dummy['ts_on_religious_activities'])\n","sorted_cp_dummy['ts_on_travel'] = np.where(sorted_cp_dummy['ts_on_travel']<0,np.NaN,sorted_cp_dummy['ts_on_travel'])\n","sorted_cp_dummy['ts_on_work_as_unpaid_trainee'] = np.where(sorted_cp_dummy['ts_on_work_as_unpaid_trainee']<0,np.NaN,sorted_cp_dummy['ts_on_work_as_unpaid_trainee'])\n","sorted_cp_dummy['ts_on_work_as_unpaid_volunteer'] = np.where(sorted_cp_dummy['ts_on_work_as_unpaid_volunteer']<0,np.NaN,sorted_cp_dummy['ts_on_work_as_unpaid_volunteer'])\n","sorted_cp_dummy['ts_on_work_for_employer'] = np.where(sorted_cp_dummy['ts_on_work_for_employer']<0,np.NaN,sorted_cp_dummy['ts_on_work_for_employer'])\n","sorted_cp_dummy['ts_on_work_for_hh_n_mem'] = np.where(sorted_cp_dummy['ts_on_work_for_hh_n_mem']<0,np.NaN,sorted_cp_dummy['ts_on_work_for_hh_n_mem'])\n","sorted_cp_dummy['ts_with_frnds'] = np.where(sorted_cp_dummy['ts_with_frnds']<0,np.NaN,sorted_cp_dummy['ts_with_frnds'])\n","\n","# sorted_cp_dummy['ts_on_indoor_entmt'].value_counts().sum()\n","\n","# setting all zeros to np.NaN\n","sorted_cp_dummy['ts_on_indoor_entmt_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_indoor_entmt']==0,np.NaN,sorted_cp_dummy['ts_on_indoor_entmt'])\n","sorted_cp_dummy['ts_on_learning_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_learning']==0,np.NaN,sorted_cp_dummy['ts_on_learning'])\n","sorted_cp_dummy['ts_on_oth_activities_for_self_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_oth_activities_for_self']==0,np.NaN,sorted_cp_dummy['ts_on_oth_activities_for_self'])\n","sorted_cp_dummy['ts_on_outdoor_sports_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_outdoor_sports']==0,np.NaN,sorted_cp_dummy['ts_on_outdoor_sports'])\n","sorted_cp_dummy['ts_on_religious_activities_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_religious_activities']==0,np.NaN,sorted_cp_dummy['ts_on_religious_activities'])\n","sorted_cp_dummy['ts_on_travel_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_travel']==0,np.NaN,sorted_cp_dummy['ts_on_travel'])\n","sorted_cp_dummy['ts_on_work_as_unpaid_trainee_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_work_as_unpaid_trainee']==0,np.NaN,sorted_cp_dummy['ts_on_work_as_unpaid_trainee'])\n","sorted_cp_dummy['ts_on_work_as_unpaid_volunteer_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_work_as_unpaid_volunteer']==0,np.NaN,sorted_cp_dummy['ts_on_work_as_unpaid_volunteer'])\n","sorted_cp_dummy['ts_on_work_for_employer_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_work_for_employer']==0,np.NaN,sorted_cp_dummy['ts_on_work_for_employer'])\n","sorted_cp_dummy['ts_on_work_for_hh_n_mem_only_ptcpt'] = np.where(sorted_cp_dummy['ts_on_work_for_hh_n_mem']==0,np.NaN,sorted_cp_dummy['ts_on_work_for_hh_n_mem'])\n","sorted_cp_dummy['ts_with_frnds_only_ptcpt'] = np.where(sorted_cp_dummy['ts_with_frnds']==0,np.NaN,sorted_cp_dummy['ts_with_frnds'])\n","\n","# sorted_cp_dummy['ts_on_indoor_entmt_only_ptcpt'].value_counts().sum()\n","\n","# setting all np.NaN to zeros\n","sorted_cp_dummy['ts_on_indoor_entmt_all_NAN_zeros'] = sorted_cp_dummy['ts_on_indoor_entmt'].fillna(0)\n","sorted_cp_dummy['ts_on_learning_all_NAN_zeros'] = sorted_cp_dummy['ts_on_learning'].fillna(0)\n","sorted_cp_dummy['ts_on_oth_activities_for_self_all_NAN_zeros'] = sorted_cp_dummy['ts_on_oth_activities_for_self'].fillna(0)\n","sorted_cp_dummy['ts_on_outdoor_sports_all_NAN_zeros'] = sorted_cp_dummy['ts_on_outdoor_sports'].fillna(0)\n","sorted_cp_dummy['ts_on_religious_activities_all_NAN_zeros'] = sorted_cp_dummy['ts_on_religious_activities'].fillna(0)\n","sorted_cp_dummy['ts_on_travel_all_NAN_zeros'] = sorted_cp_dummy['ts_on_travel'].fillna(0)\n","sorted_cp_dummy['ts_on_work_as_unpaid_trainee_all_NAN_zeros'] = sorted_cp_dummy['ts_on_work_as_unpaid_trainee'].fillna(0)\n","sorted_cp_dummy['ts_on_work_as_unpaid_volunteer_all_NAN_zeros'] = sorted_cp_dummy['ts_on_work_as_unpaid_volunteer'].fillna(0)\n","sorted_cp_dummy['ts_on_work_for_employer_all_NAN_zeros'] = sorted_cp_dummy['ts_on_work_for_employer'].fillna(0)\n","sorted_cp_dummy['ts_on_work_for_hh_n_mem_all_NAN_zeros'] = sorted_cp_dummy['ts_on_work_for_hh_n_mem'].fillna(0)\n","sorted_cp_dummy['ts_with_frnds_all_NAN_zeros'] = sorted_cp_dummy['ts_with_frnds'].fillna(0)\n","\n","# sorted_cp_dummy['ts_on_indoor_entmt_all_NAN_zeros'].value_counts().sum()\n","\n","sorted_cp_dummy['total_ts'] = sorted_cp_dummy['ts_on_indoor_entmt_all_NAN_zeros'] + sorted_cp_dummy['ts_on_learning_all_NAN_zeros'] + sorted_cp_dummy['ts_on_oth_activities_for_self_all_NAN_zeros'] + sorted_cp_dummy['ts_on_outdoor_sports_all_NAN_zeros'] + sorted_cp_dummy['ts_on_religious_activities_all_NAN_zeros'] + sorted_cp_dummy['ts_on_travel_all_NAN_zeros'] + sorted_cp_dummy['ts_on_work_as_unpaid_trainee_all_NAN_zeros'] + sorted_cp_dummy['ts_on_work_as_unpaid_volunteer_all_NAN_zeros'] + sorted_cp_dummy['ts_on_work_for_employer_all_NAN_zeros'] + sorted_cp_dummy['ts_on_work_for_hh_n_mem_all_NAN_zeros'] + sorted_cp_dummy['ts_with_frnds_all_NAN_zeros']\n","sorted_cp_dummy['total_ts'].value_counts()\n","\n","# total_ts\n","# 24.0    3543163\n","# 0.0      181354\n","# 16.0         51\n","# 17.0         11\n","# 18.0          7\n","# 15.0          6\n","# 15.5          4\n","# 21.0          3\n","# 20.5          3\n","# 20.0          3\n","# 16.5          2\n","# 19.0          2\n","# 14.0          2\n","# 17.5          2\n","# 18.5          1\n","# Name: count, dtype: int64"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"data":{"text/plain":["new_caste_category\n","OBC                   197382\n","Upper Caste           118287\n","SC                    106516\n","Intermediate Caste     46160\n","ST                     28793\n","Not Stated              4735\n","Not Applicable            35\n","Name: count, dtype: int64"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["religion_mode_frame['new_caste_category'].value_counts()"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["sorted_cp_dummy.to_stata('sorted_cp_dummy.dta')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Column `new_religion` cannot be exported.\n\nOnly string-like object arrays\ncontaining all strings or a mix of strings and None can be exported.\nObject arrays containing only null values are prohibited. Other object\ntypes cannot be exported and must first be converted to one of the\nsupported types.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m affected_cp_dummy \u001b[38;5;241m=\u001b[39m sorted_cp_dummy[sorted_cp_dummy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhether_shock_hhid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[0;32m----> 2\u001b[0m affected_cp_dummy\u001b[38;5;241m.\u001b[39mto_stata(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maffected_cp_dummy.dta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:2672\u001b[0m, in \u001b[0;36mDataFrame.to_stata\u001b[0;34m(self, path, convert_dates, write_index, byteorder, time_stamp, data_label, variable_labels, version, convert_strl, compression, storage_options, value_labels)\u001b[0m\n\u001b[1;32m   2668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m118\u001b[39m:\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;66;03m# Specifying the version is only supported for UTF8 (118 or 119)\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m version\n\u001b[0;32m-> 2672\u001b[0m writer \u001b[38;5;241m=\u001b[39m statawriter(\n\u001b[1;32m   2673\u001b[0m     path,\n\u001b[1;32m   2674\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2675\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[1;32m   2676\u001b[0m     byteorder\u001b[38;5;241m=\u001b[39mbyteorder,\n\u001b[1;32m   2677\u001b[0m     time_stamp\u001b[38;5;241m=\u001b[39mtime_stamp,\n\u001b[1;32m   2678\u001b[0m     data_label\u001b[38;5;241m=\u001b[39mdata_label,\n\u001b[1;32m   2679\u001b[0m     write_index\u001b[38;5;241m=\u001b[39mwrite_index,\n\u001b[1;32m   2680\u001b[0m     variable_labels\u001b[38;5;241m=\u001b[39mvariable_labels,\n\u001b[1;32m   2681\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   2682\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   2683\u001b[0m     value_labels\u001b[38;5;241m=\u001b[39mvalue_labels,\n\u001b[1;32m   2684\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2685\u001b[0m )\n\u001b[1;32m   2686\u001b[0m writer\u001b[38;5;241m.\u001b[39mwrite_file()\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/stata.py:2350\u001b[0m, in \u001b[0;36mStataWriter.__init__\u001b[0;34m(self, fname, data, convert_dates, write_index, byteorder, time_stamp, data_label, variable_labels, compression, storage_options, value_labels)\u001b[0m\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_converted_names: \u001b[38;5;28mdict\u001b[39m[Hashable, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2349\u001b[0m \u001b[38;5;66;03m# attach nobs, nvars, data, varlist, typlist\u001b[39;00m\n\u001b[0;32m-> 2350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_pandas(data)\n\u001b[1;32m   2351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/stata.py:2632\u001b[0m, in \u001b[0;36mStataWriter._prepare_pandas\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2629\u001b[0m     dtypes[key] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(new_type)\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;66;03m# Verify object arrays are strings and encode to bytes\u001b[39;00m\n\u001b[0;32m-> 2632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_strings()\n\u001b[1;32m   2634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_formats_and_types(dtypes)\n\u001b[1;32m   2636\u001b[0m \u001b[38;5;66;03m# set the given format for the datetime cols\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/stata.py:2663\u001b[0m, in \u001b[0;36mStataWriter._encode_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2661\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ((inferred_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   2662\u001b[0m                     col \u001b[38;5;241m=\u001b[39m column\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m-> 2663\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2664\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m \u001b[38;5;124mColumn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be exported.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOnly string-like object arrays\u001b[39m\n\u001b[1;32m   2666\u001b[0m \u001b[38;5;124mcontaining all strings or a mix of strings and None can be exported.\u001b[39m\n\u001b[1;32m   2667\u001b[0m \u001b[38;5;124mObject arrays containing only null values are prohibited. Other object\u001b[39m\n\u001b[1;32m   2668\u001b[0m \u001b[38;5;124mtypes cannot be exported and must first be converted to one of the\u001b[39m\n\u001b[1;32m   2669\u001b[0m \u001b[38;5;124msupported types.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   2670\u001b[0m                     )\n\u001b[1;32m   2671\u001b[0m                 encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[col]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding)\n\u001b[1;32m   2672\u001b[0m                 \u001b[38;5;66;03m# If larger than _max_string_length do nothing\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: Column `new_religion` cannot be exported.\n\nOnly string-like object arrays\ncontaining all strings or a mix of strings and None can be exported.\nObject arrays containing only null values are prohibited. Other object\ntypes cannot be exported and must first be converted to one of the\nsupported types."]}],"source":["affected_cp_dummy = sorted_cp_dummy[sorted_cp_dummy['whether_shock_hhid'] == True]\n","affected_cp_dummy.to_stata('affected_cp_dummy.dta')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# affected_cp_dummy = pd.read_stata(filepath_or_buffer = '/Users/gulatii16/Library/CloudStorage/GoogleDrive-himanshu.gulatii16@gmail.com/My Drive/0 g [n]/5 Part Time Works/6 Shila Work/5 Exogenous Shock Study_CMIE/affected_cp_dummy_04012024.dta')"]},{"cell_type":"markdown","metadata":{"id":"taDvvLa9q-5p"},"source":["\n","<a name = Section6></a>\n","### **3. Exploratory Data Analysis**\n","##### This section is emphasised on asking the right questions and perform analysis using the data.\n","---"]},{"cell_type":"markdown","metadata":{"id":"Pqk4cV2wrIIZ"},"source":["---\n","<a name = Section7></a>\n","### **4. Summarization: Conclusion & Actionable Insights**\n","---"]},{"cell_type":"markdown","metadata":{},"source":["#### **Saving the data into html:**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !jupyter nbconvert Commutation_Analysis.ipynb --no-input --to html"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Load Profile Analysis Report.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.0.0"},"vscode":{"interpreter":{"hash":"74356f11c2d6339eb98855f04bac344a906384aa1ecc699de17554f782a40b91"}}},"nbformat":4,"nbformat_minor":0}
